{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b029c25c-e73a-47a8-a596-2923d65b93ec",
   "metadata": {},
   "source": [
    "# BiLSTM-based classifier for Semantic Role Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0091965c-753f-43fd-99dd-4c2113e98839",
   "metadata": {},
   "source": [
    "Importing needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6aeb704-3be9-44f4-ad2b-2307f11afc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras import Sequential, Model, Input, optimizers\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "# changed line:\n",
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# reproducibility \n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c8df14-e5df-4469-afe5-a2ea326369d8",
   "metadata": {},
   "source": [
    "### 1. Let's begin by loading the dataset and defining paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a364e63-5d18-4965-9105-3f86039db074",
   "metadata": {},
   "source": [
    "The dataset used for training is the English portion of the Universal Proposition Banks v1.0 (https://github.com/UniversalPropositions/UP-1.0). The paths to the evaluation, training and test set are defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cd6ee42-cabb-4470-a074-b4bc48ae203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the CONLLU data\n",
    "path_train ='Data/en_ewt-up-train.conllu' \n",
    "path_eval = 'Data/en_ewt-up-dev.conllu' \n",
    "path_test = 'Data/en_ewt-up-test.conllu'\n",
    "paths = [path_train, path_eval, path_test]\n",
    "\n",
    "# Change to test when you are evaluating on test-set:\n",
    "eval_split = 'dev'\n",
    "\n",
    "# Embedding model\n",
    "path_emb = 'Models/GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "# Output path model\n",
    "output_path = 'bilstm-out1.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288ff221-423b-425d-be13-0e1d016f6740",
   "metadata": {},
   "source": [
    "For the implementation of the BiLSTM classifier, the data should be converted to an adapted .connlu file. The commented and empty sentences should be removed. Also, the sentences are repeated as many times as it contains predicates. The next functions helps us in doing so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a18ded2-bacb-4edb-9614-6946023af43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conllu_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads a CoNLL-U formatted file and returns a list of sentences, where each sentence is a list of token information.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The file path of the CoNLL-U file to be read.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of sentences, where each sentence is represented as a list of token information.\n",
    "    \"\"\"\n",
    "    \n",
    "    sentences = []\n",
    "    with open(file_path, \"r\", encoding = \"utf-8\") as file:\n",
    "        sentence = []\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            \n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            \n",
    "            if not line:\n",
    "                if sentence: \n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "            \n",
    "            else: \n",
    "                sentence.append(line.split(\"\\t\"))\n",
    "                \n",
    "        if sentence:\n",
    "            sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "def copy_predicates(file_path):\n",
    "    \"\"\"\n",
    "    Reads a CoNLL-U formatted file, finds sentences with multiple predicates, and creates new sentences by copying the original \n",
    "    sentence and changing the predicate values.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The file path of the CoNLL-U file to be read.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of modified sentences, where each modified sentence is represented as a list of token information.\n",
    "    \"\"\"\n",
    "    \n",
    "    sentences = read_conllu_file(file_path)\n",
    "    new_sentences = []\n",
    "    \n",
    "    for sentence in sentences: \n",
    "        #print(sentence)\n",
    "        predicate_values = list([columns[10] for columns in sentence if len(columns) >= 11])\n",
    "        predicate_values = [value for value in predicate_values if value != \"_\"]\n",
    "\n",
    "        if len(predicate_values) <= 1:\n",
    "            new_sentences.append(sentence)\n",
    "        elif len(predicate_values) > 1: \n",
    "            for i, pred in enumerate(predicate_values):\n",
    "                b = i + 1\n",
    "                df = pd.DataFrame(sentence)\n",
    "                df_2 = df.iloc[:, :11].copy()\n",
    "                new_col = df.iloc[:, (10+b)]\n",
    "                df_2[11] = new_col\n",
    "                new_sentence = df_2.values.tolist()\n",
    "                new_sentences.append(new_sentence)\n",
    "    return new_sentences\n",
    "\n",
    "def create_adapted_conll_files(file_paths):\n",
    "    \"\"\"\n",
    "    Creates new CoNLL-U formatted files by adapting the original files with the 'copy_predicates' function. \n",
    "\n",
    "    Args:\n",
    "        file_paths (list): A list of file paths to CoNLL-U formatted files to be adapted.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of file paths to the newly created adapted CoNLL-U files.\n",
    "    \"\"\"\n",
    "    \n",
    "    adapted_paths = []\n",
    "    for file_path in file_paths:\n",
    "        sentences = copy_predicates(file_path)\n",
    "        \n",
    "        output_file = file_path.replace(\".conllu\", \"_adapted.conllu\")\n",
    "\n",
    "        with open(output_file, \"w\", encoding = \"utf-8\") as outfile:\n",
    "            for sentence in sentences:\n",
    "                for columns in sentence:\n",
    "                    if None in columns:\n",
    "                        continue\n",
    "                    else:\n",
    "                        outfile.write(\"\\t\".join(columns) + \"\\n\")\n",
    "        adapted_paths.append(output_file)\n",
    "    \n",
    "    return adapted_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0986896e-a4de-4526-ac22-f7325811311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapted_paths = create_adapted_conll_files(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badd83d6-c472-4a3c-b3af-a340b2d93315",
   "metadata": {},
   "source": [
    "The adapted conll files are now read into a dataframe with use of the next defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "628c2ba1-f432-4657-b823-85b8dc3f51af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_conll_to_df(paths):\n",
    "    \"\"\"\n",
    "    Converts a list of CoNLL files to a pandas dataframe with additional columns for sentence ID and split ID.\n",
    "\n",
    "    Args:\n",
    "        paths (list): A list of file paths to CoNLL files.\n",
    "\n",
    "    Returns:\n",
    "        final_dataframe (pandas.DataFrame): A pandas dataframe containing the concatenated data from all input files with\n",
    "                                             two additional columns, \"# SENTENCE\" and \"SPLIT\".\n",
    "    \"\"\"\n",
    "    \n",
    "    complete_dataframe  = []\n",
    "    sentence_id = 0\n",
    "    adapted_paths = create_adapted_conll_files(paths)\n",
    "    \n",
    "    for path in paths:\n",
    "        suffix = path.split('.')[0]\n",
    "        split = (suffix.split('-')[-1]).split('_')[0]\n",
    "        print(split)\n",
    "    \n",
    "        df = pd.read_csv(path, delimiter='\\t', header=None, on_bad_lines = \"skip\", engine = \"python\",\n",
    "                    names=['ID', 'TOKEN', 'LEMMA', 'POS-UNIV', 'POS', 'MORPH', 'HEAD', 'BASIC-DEP', 'ENH-DEP', \n",
    "                           'SPACE', 'PREDICATE', 'LABEL'])\n",
    "        df.dropna()\n",
    "        # Adds the SPLIT column to the dataframe\n",
    "        df['SPLIT'] = split\n",
    "    \n",
    "        # Adds the # SENTENCE column to the dataframe\n",
    "        df['# SENTENCE'] = 0\n",
    "        for index, row in df.iterrows():\n",
    "            if row['ID'] == 1:\n",
    "                sentence_id += 1\n",
    "            df.at[index, '# SENTENCE'] = sentence_id\n",
    "        \n",
    "        # print(len(df))\n",
    "        complete_dataframe.append(df)\n",
    "        \n",
    "    \n",
    "    final_dataframe = pd.concat(complete_dataframe, ignore_index=True)\n",
    "\n",
    "    return final_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6771ad2a-d836-44b4-94a1-0bd0d94bd2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/en_ewt-up-train_adapted.conllu',\n",
       " 'Data/en_ewt-up-dev_adapted.conllu',\n",
       " 'Data/en_ewt-up-test_adapted.conllu']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapted_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f226565-8716-4876-bd71-82a43b4c6970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "dev\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "data = convert_conll_to_df(adapted_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3ed1489-dc20-4bc8-aadf-4e29037bf66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TOKEN</th>\n",
       "      <th>LEMMA</th>\n",
       "      <th>POS-UNIV</th>\n",
       "      <th>POS</th>\n",
       "      <th>MORPH</th>\n",
       "      <th>HEAD</th>\n",
       "      <th>BASIC-DEP</th>\n",
       "      <th>ENH-DEP</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>PREDICATE</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>SPLIT</th>\n",
       "      <th># SENTENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Al</td>\n",
       "      <td>Al</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>0:root</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>HYPH</td>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>punct</td>\n",
       "      <td>1:punct</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Zaman</td>\n",
       "      <td>Zaman</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>1</td>\n",
       "      <td>flat</td>\n",
       "      <td>1:flat</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:</td>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>punct</td>\n",
       "      <td>1:punct</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>American</td>\n",
       "      <td>american</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Degree=Pos</td>\n",
       "      <td>6</td>\n",
       "      <td>amod</td>\n",
       "      <td>6:amod</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237802</th>\n",
       "      <td>16.0</td>\n",
       "      <td>suggesting</td>\n",
       "      <td>suggest</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VerbForm=Ger</td>\n",
       "      <td>7</td>\n",
       "      <td>conj</td>\n",
       "      <td>5:advcl:in|7:conj:and</td>\n",
       "      <td>_</td>\n",
       "      <td>suggest.01</td>\n",
       "      <td>_</td>\n",
       "      <td>test</td>\n",
       "      <td>52978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237803</th>\n",
       "      <td>17.0</td>\n",
       "      <td>exercises</td>\n",
       "      <td>exercise</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Number=Plur</td>\n",
       "      <td>16</td>\n",
       "      <td>obj</td>\n",
       "      <td>16:obj</td>\n",
       "      <td>_</td>\n",
       "      <td>exercise.02</td>\n",
       "      <td>ARG1</td>\n",
       "      <td>test</td>\n",
       "      <td>52978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237804</th>\n",
       "      <td>18.0</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "      <td>TO</td>\n",
       "      <td>_</td>\n",
       "      <td>19</td>\n",
       "      <td>mark</td>\n",
       "      <td>19:mark</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>test</td>\n",
       "      <td>52978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237805</th>\n",
       "      <td>19.0</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VB</td>\n",
       "      <td>VerbForm=Inf</td>\n",
       "      <td>17</td>\n",
       "      <td>acl</td>\n",
       "      <td>17:acl:to</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "      <td>use.01</td>\n",
       "      <td>V</td>\n",
       "      <td>test</td>\n",
       "      <td>52978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237806</th>\n",
       "      <td>20.0</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>_</td>\n",
       "      <td>2</td>\n",
       "      <td>punct</td>\n",
       "      <td>2:punct</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>test</td>\n",
       "      <td>52978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1237807 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID       TOKEN     LEMMA POS-UNIV   POS         MORPH HEAD  \\\n",
       "0         1.0          Al        Al    PROPN   NNP   Number=Sing    0   \n",
       "1         2.0           -         -    PUNCT  HYPH             _    1   \n",
       "2         3.0       Zaman     Zaman    PROPN   NNP   Number=Sing    1   \n",
       "3         4.0           :         :    PUNCT     :             _    1   \n",
       "4         5.0    American  american      ADJ    JJ    Degree=Pos    6   \n",
       "...       ...         ...       ...      ...   ...           ...  ...   \n",
       "1237802  16.0  suggesting   suggest     VERB   VBG  VerbForm=Ger    7   \n",
       "1237803  17.0   exercises  exercise     NOUN   NNS   Number=Plur   16   \n",
       "1237804  18.0          to        to     PART    TO             _   19   \n",
       "1237805  19.0         use       use     VERB    VB  VerbForm=Inf   17   \n",
       "1237806  20.0           .         .    PUNCT     .             _    2   \n",
       "\n",
       "        BASIC-DEP                ENH-DEP          SPACE    PREDICATE LABEL  \\\n",
       "0            root                 0:root  SpaceAfter=No            _     _   \n",
       "1           punct                1:punct  SpaceAfter=No            _     _   \n",
       "2            flat                 1:flat              _            _     _   \n",
       "3           punct                1:punct              _            _     _   \n",
       "4            amod                 6:amod              _            _     _   \n",
       "...           ...                    ...            ...          ...   ...   \n",
       "1237802      conj  5:advcl:in|7:conj:and              _   suggest.01     _   \n",
       "1237803       obj                 16:obj              _  exercise.02  ARG1   \n",
       "1237804      mark                19:mark              _            _     _   \n",
       "1237805       acl              17:acl:to  SpaceAfter=No       use.01     V   \n",
       "1237806     punct                2:punct              _            _     _   \n",
       "\n",
       "         SPLIT  # SENTENCE  \n",
       "0        train           1  \n",
       "1        train           1  \n",
       "2        train           1  \n",
       "3        train           1  \n",
       "4        train           1  \n",
       "...        ...         ...  \n",
       "1237802   test       52978  \n",
       "1237803   test       52978  \n",
       "1237804   test       52978  \n",
       "1237805   test       52978  \n",
       "1237806   test       52978  \n",
       "\n",
       "[1237807 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fb2c93f-8a6a-4ac7-9de6-49fe4ddb2901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_             1066210\n",
       "V               50002\n",
       "ARG1            34050\n",
       "ARG0            18638\n",
       "ARG2            12104\n",
       "               ...   \n",
       "C-ARGM-PRP          2\n",
       "C-ARGM-ADV          1\n",
       "C-ARGM-COM          1\n",
       "C-ARGM-GOL          1\n",
       "R-ARGM-ADJ          1\n",
       "Name: LABEL, Length: 61, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['LABEL'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0469790e-8c8b-4728-88f9-e4c6a74b4a30",
   "metadata": {},
   "source": [
    "### 2. Extract the mappings for the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928dfa7a-cb88-4bdb-9097-f6b9caff66be",
   "metadata": {},
   "source": [
    "To train the BiLSTM classifier, two mappings are used as given below: \n",
    "- {token} to {token id}: address the row in the embeddings matrix for the current token\n",
    "- {tag} to {tag id}: one-hot ground truth probability distribution vectors for computing the loss at the network's output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa99649f-d7c2-49e8-8231-fd2d81d440c8",
   "metadata": {},
   "source": [
    "The next step is desired in any machine learning model, including the BiLSTM classifier, which requires integers as input. The function below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0f0e34b-7fe2-47cb-9865-dbbc3b8623a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def get_dict_map(data, token_or_tag):\n",
    "    \"\"\"\n",
    "    Create two dictionaries to map tokens or tags to indices and vice versa.\n",
    "\n",
    "    Args:\n",
    "    - data (pandas.DataFrame): DataFrame containing the token and label columns.\n",
    "    - token_or_tag \n",
    "    \"\"\" \n",
    "    \n",
    "    tok2idx = {}\n",
    "    idx2tok = {}\n",
    "    \n",
    "    if token_or_tag == 'TOKEN':\n",
    "        vocab = list(set(data['TOKEN'].to_list()))\n",
    "    else:\n",
    "        vocab = list(set(data['LABEL'].to_list()))\n",
    "    \n",
    "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
    "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
    "    \n",
    "    return tok2idx, idx2tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bce15d1-6dff-45d2-a3da-a31f1c5c843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token2idx, idx2token = get_dict_map(data, 'TOKEN')\n",
    "tag2idx, idx2tag = get_dict_map(data, 'LABEL')\n",
    "\n",
    "n_vocab, n_tags = len(token2idx), len(tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97ff6f42-9bae-4fce-acbb-cdc5461a570c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22967 62\n"
     ]
    }
   ],
   "source": [
    "print(n_vocab, n_tags) #TODO: WHY NOT 60 TAGS? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44cc429-7c70-4fc5-8037-15c3bdbc4a9f",
   "metadata": {},
   "source": [
    "Two new index columns are added for the newly created variables WORD_IDX and TAG_IDX. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35c21d9e-3dc3-48e3-ac26-dd434568d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the index information to the dataframe\n",
    "data['WORD_IDX'] = data['TOKEN'].map(token2idx)\n",
    "data['TAG_IDX'] = data['LABEL'].map(tag2idx)\n",
    "data['PRED_IDX'] = data['LABEL'].apply(lambda x: 1 if x == 'V' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49f22116-1fae-4d07-ad73-800d723984f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TOKEN</th>\n",
       "      <th>LEMMA</th>\n",
       "      <th>POS-UNIV</th>\n",
       "      <th>POS</th>\n",
       "      <th>MORPH</th>\n",
       "      <th>HEAD</th>\n",
       "      <th>BASIC-DEP</th>\n",
       "      <th>ENH-DEP</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>PREDICATE</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>SPLIT</th>\n",
       "      <th># SENTENCE</th>\n",
       "      <th>WORD_IDX</th>\n",
       "      <th>TAG_IDX</th>\n",
       "      <th>PRED_IDX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Al</td>\n",
       "      <td>Al</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>0:root</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>5509</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>HYPH</td>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>punct</td>\n",
       "      <td>1:punct</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>8001</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Zaman</td>\n",
       "      <td>Zaman</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>1</td>\n",
       "      <td>flat</td>\n",
       "      <td>1:flat</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>5818</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:</td>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>punct</td>\n",
       "      <td>1:punct</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>11689</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>American</td>\n",
       "      <td>american</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Degree=Pos</td>\n",
       "      <td>6</td>\n",
       "      <td>amod</td>\n",
       "      <td>6:amod</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>16282</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID     TOKEN     LEMMA POS-UNIV   POS        MORPH HEAD BASIC-DEP  \\\n",
       "0  1.0        Al        Al    PROPN   NNP  Number=Sing    0      root   \n",
       "1  2.0         -         -    PUNCT  HYPH            _    1     punct   \n",
       "2  3.0     Zaman     Zaman    PROPN   NNP  Number=Sing    1      flat   \n",
       "3  4.0         :         :    PUNCT     :            _    1     punct   \n",
       "4  5.0  American  american      ADJ    JJ   Degree=Pos    6      amod   \n",
       "\n",
       "   ENH-DEP          SPACE PREDICATE LABEL  SPLIT  # SENTENCE  WORD_IDX  \\\n",
       "0   0:root  SpaceAfter=No         _     _  train           1      5509   \n",
       "1  1:punct  SpaceAfter=No         _     _  train           1      8001   \n",
       "2   1:flat              _         _     _  train           1      5818   \n",
       "3  1:punct              _         _     _  train           1     11689   \n",
       "4   6:amod              _         _     _  train           1     16282   \n",
       "\n",
       "   TAG_IDX  PRED_IDX  \n",
       "0       60         0  \n",
       "1       60         0  \n",
       "2       60         0  \n",
       "3       60         0  \n",
       "4       60         0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e064b-7a86-475a-8c08-85481387628b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Integrate the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54246231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_emb(path_emb):\n",
    "    w2v_model = KeyedVectors.load_word2vec_format(path_emb, binary=True)\n",
    "    emb_dim = 300\n",
    "    embedding_matrix = np.zeros((len(token2idx) + 1, emb_dim))\n",
    "    print(embedding_matrix.shape)\n",
    "    for word, i in token2idx.items():\n",
    "        if word in w2v_model.key_to_index:\n",
    "            embedding_vector = w2v_model[word]\n",
    "        else:\n",
    "            embedding_vector = None\n",
    "\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    return w2v_model, emd_dim, embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a73eca7-98f4-4364-91e5-32bba3b6b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format(path_emb, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a2babb8-7f67-4117-9157-111710b5bdb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22968, 300)\n"
     ]
    }
   ],
   "source": [
    "# Create embedding matrix with zero vectors for oov words\n",
    "emb_dim = 300\n",
    "embedding_matrix = np.zeros((len(token2idx) + 1, emb_dim))\n",
    "print(embedding_matrix.shape)\n",
    "for word, i in token2idx.items():\n",
    "    if word in w2v_model.key_to_index:\n",
    "        embedding_vector = w2v_model[word]\n",
    "    else:\n",
    "        embedding_vector = None\n",
    "        \n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "703b55ba-eac6-4d69-afbc-5ef23d9451a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22968, 300)\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# Check dimensions, store number of vector dimensions in variable\n",
    "print(embedding_matrix.shape)\n",
    "emb_dim = embedding_matrix.shape[1]\n",
    "print(emb_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec142c4-b2bd-4fd6-8d1e-085a222d228c",
   "metadata": {},
   "source": [
    "### 4. Transform columns to extract sequential data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0507109-f5df-41ad-9624-56494400179c",
   "metadata": {},
   "source": [
    "For making the recurrent neural network of it's best use, it'is best to collect tokens into arrays in the respective sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab2edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_seq(data):\n",
    "    data_fillna = data.fillna(method='ffill', axis=0)\n",
    "    data_group = data_fillna.groupby(['# SENTENCE'],as_index=False)['ID', 'TOKEN', 'LEMMA', 'POS-UNIV', 'POS', 'MORPH', 'HEAD', 'BASIC-DEP', \n",
    "  'ENH-DEP', 'SPACE', 'PREDICATE', 'LABEL', 'SPLIT', '# SENTENCE', 'WORD_IDX', 'TAG_IDX'].agg(lambda x: list(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87f34f3c-cbd1-493c-b87e-5f55f8a2bbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TOKEN</th>\n",
       "      <th>LEMMA</th>\n",
       "      <th>POS-UNIV</th>\n",
       "      <th>POS</th>\n",
       "      <th>MORPH</th>\n",
       "      <th>HEAD</th>\n",
       "      <th>BASIC-DEP</th>\n",
       "      <th>ENH-DEP</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>PREDICATE</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>SPLIT</th>\n",
       "      <th># SENTENCE</th>\n",
       "      <th>WORD_IDX</th>\n",
       "      <th>TAG_IDX</th>\n",
       "      <th>PRED_IDX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52973</th>\n",
       "      <td>[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>[He, listens, and, is, excellent, in, diagnosi...</td>\n",
       "      <td>[he, listen, and, be, excellent, in, diagnose,...</td>\n",
       "      <td>[PRON, VERB, CCONJ, AUX, ADJ, SCONJ, VERB, PUN...</td>\n",
       "      <td>[PRP, VBZ, CC, VBZ, JJ, IN, VBG, ,, VBG, CC, V...</td>\n",
       "      <td>[Case=Nom|Gender=Masc|Number=Sing|Person=3|Pro...</td>\n",
       "      <td>[2, 0, 5, 5, 2, 7, 5, 9, 7, 11, 7, 14, 14, 7, ...</td>\n",
       "      <td>[nsubj, root, cc, cop, conj, mark, advcl, punc...</td>\n",
       "      <td>[2:nsubj|5:nsubj, 0:root, 5:cc, 5:cop, 2:conj:...</td>\n",
       "      <td>[_, _, _, _, _, _, SpaceAfter=No, _, _, _, _, ...</td>\n",
       "      <td>[_, listen.01, _, be.01, excel.01, _, diagnose...</td>\n",
       "      <td>[ARG0, _, _, _, _, _, _, _, _, _, V, _, _, ARG...</td>\n",
       "      <td>[test, test, test, test, test, test, test, tes...</td>\n",
       "      <td>[52974, 52974, 52974, 52974, 52974, 52974, 529...</td>\n",
       "      <td>[13, 17972, 1553, 18483, 18165, 16718, 18059, ...</td>\n",
       "      <td>[6, 60, 60, 60, 60, 60, 60, 60, 60, 60, 29, 60...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52974</th>\n",
       "      <td>[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>[He, listens, and, is, excellent, in, diagnosi...</td>\n",
       "      <td>[he, listen, and, be, excellent, in, diagnose,...</td>\n",
       "      <td>[PRON, VERB, CCONJ, AUX, ADJ, SCONJ, VERB, PUN...</td>\n",
       "      <td>[PRP, VBZ, CC, VBZ, JJ, IN, VBG, ,, VBG, CC, V...</td>\n",
       "      <td>[Case=Nom|Gender=Masc|Number=Sing|Person=3|Pro...</td>\n",
       "      <td>[2, 0, 5, 5, 2, 7, 5, 9, 7, 11, 7, 14, 14, 7, ...</td>\n",
       "      <td>[nsubj, root, cc, cop, conj, mark, advcl, punc...</td>\n",
       "      <td>[2:nsubj|5:nsubj, 0:root, 5:cc, 5:cop, 2:conj:...</td>\n",
       "      <td>[_, _, _, _, _, _, SpaceAfter=No, _, _, _, _, ...</td>\n",
       "      <td>[_, listen.01, _, be.01, excel.01, _, diagnose...</td>\n",
       "      <td>[_, _, _, _, _, _, _, _, _, _, _, _, ARGM-ADJ,...</td>\n",
       "      <td>[test, test, test, test, test, test, test, tes...</td>\n",
       "      <td>[52975, 52975, 52975, 52975, 52975, 52975, 529...</td>\n",
       "      <td>[13, 17972, 1553, 18483, 18165, 16718, 18059, ...</td>\n",
       "      <td>[60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 6...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52975</th>\n",
       "      <td>[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>[He, listens, and, is, excellent, in, diagnosi...</td>\n",
       "      <td>[he, listen, and, be, excellent, in, diagnose,...</td>\n",
       "      <td>[PRON, VERB, CCONJ, AUX, ADJ, SCONJ, VERB, PUN...</td>\n",
       "      <td>[PRP, VBZ, CC, VBZ, JJ, IN, VBG, ,, VBG, CC, V...</td>\n",
       "      <td>[Case=Nom|Gender=Masc|Number=Sing|Person=3|Pro...</td>\n",
       "      <td>[2, 0, 5, 5, 2, 7, 5, 9, 7, 11, 7, 14, 14, 7, ...</td>\n",
       "      <td>[nsubj, root, cc, cop, conj, mark, advcl, punc...</td>\n",
       "      <td>[2:nsubj|5:nsubj, 0:root, 5:cc, 5:cop, 2:conj:...</td>\n",
       "      <td>[_, _, _, _, _, _, SpaceAfter=No, _, _, _, _, ...</td>\n",
       "      <td>[_, listen.01, _, be.01, excel.01, _, diagnose...</td>\n",
       "      <td>[ARG0, _, _, _, _, _, _, _, _, _, _, _, _, _, ...</td>\n",
       "      <td>[test, test, test, test, test, test, test, tes...</td>\n",
       "      <td>[52976, 52976, 52976, 52976, 52976, 52976, 529...</td>\n",
       "      <td>[13, 17972, 1553, 18483, 18165, 16718, 18059, ...</td>\n",
       "      <td>[6, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52976</th>\n",
       "      <td>[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>[He, listens, and, is, excellent, in, diagnosi...</td>\n",
       "      <td>[he, listen, and, be, excellent, in, diagnose,...</td>\n",
       "      <td>[PRON, VERB, CCONJ, AUX, ADJ, SCONJ, VERB, PUN...</td>\n",
       "      <td>[PRP, VBZ, CC, VBZ, JJ, IN, VBG, ,, VBG, CC, V...</td>\n",
       "      <td>[Case=Nom|Gender=Masc|Number=Sing|Person=3|Pro...</td>\n",
       "      <td>[2, 0, 5, 5, 2, 7, 5, 9, 7, 11, 7, 14, 14, 7, ...</td>\n",
       "      <td>[nsubj, root, cc, cop, conj, mark, advcl, punc...</td>\n",
       "      <td>[2:nsubj|5:nsubj, 0:root, 5:cc, 5:cop, 2:conj:...</td>\n",
       "      <td>[_, _, _, _, _, _, SpaceAfter=No, _, _, _, _, ...</td>\n",
       "      <td>[_, listen.01, _, be.01, excel.01, _, diagnose...</td>\n",
       "      <td>[_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ...</td>\n",
       "      <td>[test, test, test, test, test, test, test, tes...</td>\n",
       "      <td>[52977, 52977, 52977, 52977, 52977, 52977, 529...</td>\n",
       "      <td>[13, 17972, 1553, 18483, 18165, 16718, 18059, ...</td>\n",
       "      <td>[60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 6...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52977</th>\n",
       "      <td>[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>[He, listens, and, is, excellent, in, diagnosi...</td>\n",
       "      <td>[he, listen, and, be, excellent, in, diagnose,...</td>\n",
       "      <td>[PRON, VERB, CCONJ, AUX, ADJ, SCONJ, VERB, PUN...</td>\n",
       "      <td>[PRP, VBZ, CC, VBZ, JJ, IN, VBG, ,, VBG, CC, V...</td>\n",
       "      <td>[Case=Nom|Gender=Masc|Number=Sing|Person=3|Pro...</td>\n",
       "      <td>[2, 0, 5, 5, 2, 7, 5, 9, 7, 11, 7, 14, 14, 7, ...</td>\n",
       "      <td>[nsubj, root, cc, cop, conj, mark, advcl, punc...</td>\n",
       "      <td>[2:nsubj|5:nsubj, 0:root, 5:cc, 5:cop, 2:conj:...</td>\n",
       "      <td>[_, _, _, _, _, _, SpaceAfter=No, _, _, _, _, ...</td>\n",
       "      <td>[_, listen.01, _, be.01, excel.01, _, diagnose...</td>\n",
       "      <td>[_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ...</td>\n",
       "      <td>[test, test, test, test, test, test, test, tes...</td>\n",
       "      <td>[52978, 52978, 52978, 52978, 52978, 52978, 529...</td>\n",
       "      <td>[13, 17972, 1553, 18483, 18165, 16718, 18059, ...</td>\n",
       "      <td>[60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 6...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      ID  \\\n",
       "52973  [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...   \n",
       "52974  [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...   \n",
       "52975  [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...   \n",
       "52976  [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...   \n",
       "52977  [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...   \n",
       "\n",
       "                                                   TOKEN  \\\n",
       "52973  [He, listens, and, is, excellent, in, diagnosi...   \n",
       "52974  [He, listens, and, is, excellent, in, diagnosi...   \n",
       "52975  [He, listens, and, is, excellent, in, diagnosi...   \n",
       "52976  [He, listens, and, is, excellent, in, diagnosi...   \n",
       "52977  [He, listens, and, is, excellent, in, diagnosi...   \n",
       "\n",
       "                                                   LEMMA  \\\n",
       "52973  [he, listen, and, be, excellent, in, diagnose,...   \n",
       "52974  [he, listen, and, be, excellent, in, diagnose,...   \n",
       "52975  [he, listen, and, be, excellent, in, diagnose,...   \n",
       "52976  [he, listen, and, be, excellent, in, diagnose,...   \n",
       "52977  [he, listen, and, be, excellent, in, diagnose,...   \n",
       "\n",
       "                                                POS-UNIV  \\\n",
       "52973  [PRON, VERB, CCONJ, AUX, ADJ, SCONJ, VERB, PUN...   \n",
       "52974  [PRON, VERB, CCONJ, AUX, ADJ, SCONJ, VERB, PUN...   \n",
       "52975  [PRON, VERB, CCONJ, AUX, ADJ, SCONJ, VERB, PUN...   \n",
       "52976  [PRON, VERB, CCONJ, AUX, ADJ, SCONJ, VERB, PUN...   \n",
       "52977  [PRON, VERB, CCONJ, AUX, ADJ, SCONJ, VERB, PUN...   \n",
       "\n",
       "                                                     POS  \\\n",
       "52973  [PRP, VBZ, CC, VBZ, JJ, IN, VBG, ,, VBG, CC, V...   \n",
       "52974  [PRP, VBZ, CC, VBZ, JJ, IN, VBG, ,, VBG, CC, V...   \n",
       "52975  [PRP, VBZ, CC, VBZ, JJ, IN, VBG, ,, VBG, CC, V...   \n",
       "52976  [PRP, VBZ, CC, VBZ, JJ, IN, VBG, ,, VBG, CC, V...   \n",
       "52977  [PRP, VBZ, CC, VBZ, JJ, IN, VBG, ,, VBG, CC, V...   \n",
       "\n",
       "                                                   MORPH  \\\n",
       "52973  [Case=Nom|Gender=Masc|Number=Sing|Person=3|Pro...   \n",
       "52974  [Case=Nom|Gender=Masc|Number=Sing|Person=3|Pro...   \n",
       "52975  [Case=Nom|Gender=Masc|Number=Sing|Person=3|Pro...   \n",
       "52976  [Case=Nom|Gender=Masc|Number=Sing|Person=3|Pro...   \n",
       "52977  [Case=Nom|Gender=Masc|Number=Sing|Person=3|Pro...   \n",
       "\n",
       "                                                    HEAD  \\\n",
       "52973  [2, 0, 5, 5, 2, 7, 5, 9, 7, 11, 7, 14, 14, 7, ...   \n",
       "52974  [2, 0, 5, 5, 2, 7, 5, 9, 7, 11, 7, 14, 14, 7, ...   \n",
       "52975  [2, 0, 5, 5, 2, 7, 5, 9, 7, 11, 7, 14, 14, 7, ...   \n",
       "52976  [2, 0, 5, 5, 2, 7, 5, 9, 7, 11, 7, 14, 14, 7, ...   \n",
       "52977  [2, 0, 5, 5, 2, 7, 5, 9, 7, 11, 7, 14, 14, 7, ...   \n",
       "\n",
       "                                               BASIC-DEP  \\\n",
       "52973  [nsubj, root, cc, cop, conj, mark, advcl, punc...   \n",
       "52974  [nsubj, root, cc, cop, conj, mark, advcl, punc...   \n",
       "52975  [nsubj, root, cc, cop, conj, mark, advcl, punc...   \n",
       "52976  [nsubj, root, cc, cop, conj, mark, advcl, punc...   \n",
       "52977  [nsubj, root, cc, cop, conj, mark, advcl, punc...   \n",
       "\n",
       "                                                 ENH-DEP  \\\n",
       "52973  [2:nsubj|5:nsubj, 0:root, 5:cc, 5:cop, 2:conj:...   \n",
       "52974  [2:nsubj|5:nsubj, 0:root, 5:cc, 5:cop, 2:conj:...   \n",
       "52975  [2:nsubj|5:nsubj, 0:root, 5:cc, 5:cop, 2:conj:...   \n",
       "52976  [2:nsubj|5:nsubj, 0:root, 5:cc, 5:cop, 2:conj:...   \n",
       "52977  [2:nsubj|5:nsubj, 0:root, 5:cc, 5:cop, 2:conj:...   \n",
       "\n",
       "                                                   SPACE  \\\n",
       "52973  [_, _, _, _, _, _, SpaceAfter=No, _, _, _, _, ...   \n",
       "52974  [_, _, _, _, _, _, SpaceAfter=No, _, _, _, _, ...   \n",
       "52975  [_, _, _, _, _, _, SpaceAfter=No, _, _, _, _, ...   \n",
       "52976  [_, _, _, _, _, _, SpaceAfter=No, _, _, _, _, ...   \n",
       "52977  [_, _, _, _, _, _, SpaceAfter=No, _, _, _, _, ...   \n",
       "\n",
       "                                               PREDICATE  \\\n",
       "52973  [_, listen.01, _, be.01, excel.01, _, diagnose...   \n",
       "52974  [_, listen.01, _, be.01, excel.01, _, diagnose...   \n",
       "52975  [_, listen.01, _, be.01, excel.01, _, diagnose...   \n",
       "52976  [_, listen.01, _, be.01, excel.01, _, diagnose...   \n",
       "52977  [_, listen.01, _, be.01, excel.01, _, diagnose...   \n",
       "\n",
       "                                                   LABEL  \\\n",
       "52973  [ARG0, _, _, _, _, _, _, _, _, _, V, _, _, ARG...   \n",
       "52974  [_, _, _, _, _, _, _, _, _, _, _, _, ARGM-ADJ,...   \n",
       "52975  [ARG0, _, _, _, _, _, _, _, _, _, _, _, _, _, ...   \n",
       "52976  [_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ...   \n",
       "52977  [_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ...   \n",
       "\n",
       "                                                   SPLIT  \\\n",
       "52973  [test, test, test, test, test, test, test, tes...   \n",
       "52974  [test, test, test, test, test, test, test, tes...   \n",
       "52975  [test, test, test, test, test, test, test, tes...   \n",
       "52976  [test, test, test, test, test, test, test, tes...   \n",
       "52977  [test, test, test, test, test, test, test, tes...   \n",
       "\n",
       "                                              # SENTENCE  \\\n",
       "52973  [52974, 52974, 52974, 52974, 52974, 52974, 529...   \n",
       "52974  [52975, 52975, 52975, 52975, 52975, 52975, 529...   \n",
       "52975  [52976, 52976, 52976, 52976, 52976, 52976, 529...   \n",
       "52976  [52977, 52977, 52977, 52977, 52977, 52977, 529...   \n",
       "52977  [52978, 52978, 52978, 52978, 52978, 52978, 529...   \n",
       "\n",
       "                                                WORD_IDX  \\\n",
       "52973  [13, 17972, 1553, 18483, 18165, 16718, 18059, ...   \n",
       "52974  [13, 17972, 1553, 18483, 18165, 16718, 18059, ...   \n",
       "52975  [13, 17972, 1553, 18483, 18165, 16718, 18059, ...   \n",
       "52976  [13, 17972, 1553, 18483, 18165, 16718, 18059, ...   \n",
       "52977  [13, 17972, 1553, 18483, 18165, 16718, 18059, ...   \n",
       "\n",
       "                                                 TAG_IDX  \\\n",
       "52973  [6, 60, 60, 60, 60, 60, 60, 60, 60, 60, 29, 60...   \n",
       "52974  [60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 6...   \n",
       "52975  [6, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60...   \n",
       "52976  [60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 6...   \n",
       "52977  [60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 6...   \n",
       "\n",
       "                                                PRED_IDX  \n",
       "52973  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "52974  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "52975  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "52976  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "52977  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fills NaN in the SENTENCE # column using ffill in fillna\n",
    "data_fillna = data.fillna(method='ffill', axis=0)\n",
    "\n",
    "# Groups the # SENTENCE columns to get an array of tokens and tags\n",
    "data_group = data_fillna.groupby(\n",
    "['# SENTENCE'],as_index=False\n",
    ")['ID', 'TOKEN', 'LEMMA', 'POS-UNIV', 'POS', 'MORPH', 'HEAD', 'BASIC-DEP', \n",
    "  'ENH-DEP', 'SPACE', 'PREDICATE', 'LABEL', 'SPLIT', '# SENTENCE', 'WORD_IDX', 'TAG_IDX'].agg(lambda x: list(x))\n",
    "# Visualise data\n",
    "data_group.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5744dc96-f632-40d3-8cd1-32904e24c783",
   "metadata": {},
   "source": [
    "### 5. Split the dataset into the different splits after padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49ce77d4-f282-4e9a-9649-de584280ee78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation based on: test \n",
      "train_tokens length: 42200 \n",
      "train_tags length: 42200 \n",
      "train_preds length: 42200 \n",
      "eval_tokens: 5338 \n",
      "eval_tags: 5338 \n",
      "eval_preds: 5338\n"
     ]
    }
   ],
   "source": [
    "def get_pad_train_test_val(data_group, data, eval_split=\"dev\", n_vocab=n_vocab):\n",
    "    \"\"\"\n",
    "    The function get_pad_train_test_val pads the token and tag sequences with zeros and generates one-hot encoded tags \n",
    "    for the input data. It then splits the dataset into train and evaluation sets based on the split ratio provided.\n",
    "\n",
    "    Args:\n",
    "\n",
    "    - data_group (pandas.DataFrame): A dataframe containing token and tag sequences, split information, and precomputed token and tag indices.\n",
    "    - data (pandas.DataFrame): A dataframe containing token and tag sequences, split information, and precomputed token and tag indices.\n",
    "    - eval_split (str): A string indicating the split to use for evaluation data (default is \"dev\").\n",
    "    - n_vocab (int): The number of unique tokens in the token vocabulary (default is None).\n",
    "    \n",
    "    Returns:\n",
    "    - train_tokens (numpy.ndarray): containing the padded and indexed train tokens.\n",
    "    - eval_tokens (numpy.ndarray): containing the padded and indexed evaluation tokens.\n",
    "    - train_tags (numpy.ndarray): containing the one-hot encoded tags for the train data.\n",
    "    - eval_tags (numpy.ndarray): containing the one-hot encoded tags for the evaluation data.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "     # Pad tokens\n",
    "    tokens = data_group['WORD_IDX'].tolist()\n",
    "    maxlen = max([len(s) for s in tokens])\n",
    "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value = n_vocab)\n",
    "\n",
    "    #Pad Tags and convert it into one hot encoding\n",
    "    tags = data_group['TAG_IDX'].tolist()\n",
    "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int64', padding='post', value=tag2idx[\"_\"])\n",
    "    n_tags = len(tag2idx)\n",
    "    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n",
    "    \n",
    "    \n",
    "    #Split train, test and validation set\n",
    "    train_tokens, eval_tokens, train_tags, eval_tags, train_preds, eval_preds = [], [], [], [], [], []\n",
    "    for i, row in data_group.iterrows():\n",
    "        if 'train' in row['SPLIT']:\n",
    "            train_tokens.append(pad_tokens[i])\n",
    "            train_tags.append(pad_tags[i])\n",
    "        elif eval_split in row['SPLIT']:\n",
    "            eval_tokens.append(pad_tokens[i])\n",
    "            eval_tags.append(pad_tags[i])\n",
    "\n",
    "    print(\n",
    "        'evaluation based on:', eval_split,\n",
    "        '\\ntrain_tokens length:', len(train_tokens),\n",
    "        '\\ntrain_tags length:', len(train_tags),\n",
    "        '\\neval_tokens:', len(eval_tokens),\n",
    "        '\\neval_tags:', len(eval_tags),\n",
    "    )\n",
    "    \n",
    "    return np.array(train_tokens), np.array(eval_tokens), np.array(train_tags), np.array(eval_tags)\n",
    "\n",
    "train_tokens, eval_tokens, train_tags, eval_tags = get_pad_train_test_val(data_group, data, eval_split = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "327a177b-324a-416f-b6fd-eeff32516262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5338\n",
      "42200\n"
     ]
    }
   ],
   "source": [
    "print(len(eval_tokens))\n",
    "print(len(train_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff81ca79-4cb4-4c9d-b485-3073f4a8de78",
   "metadata": {},
   "source": [
    "### 6. Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e77fb5be-ff5a-413d-ba29-cdc59d3c6240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim:  22968 \n",
      "output_dim:  300 \n",
      "input_length:  558 \n",
      "n_tags:  62\n",
      "emb dim: 300\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(list(set(data['TOKEN'].to_list()))) +1\n",
    "output_dim = emb_dim # number of dimensions\n",
    "input_length = max([len(s) for s in data_group['WORD_IDX'].tolist()])\n",
    "n_tags = len(tag2idx)\n",
    "print('input_dim: ', input_dim, \n",
    "      '\\noutput_dim: ', output_dim, \n",
    "      '\\ninput_length: ', input_length, \n",
    "      '\\nn_tags: ', n_tags)\n",
    "\n",
    "print('emb dim:', emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b2757bb-2b2f-42ef-aa45-af6ac5dc6891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bilstm_lstm_model(embedding_matrix, embedding_dim):\n",
    "    \"\"\"\n",
    "    Creates a BiLSTM model with an embedding layer using the provided embedding matrix and dimensions.\n",
    "    \n",
    "    Parameters:\n",
    "    embedding_matrix (numpy array): Pre-trained embedding matrix\n",
    "    embedding_dim (int): Dimensions of the embedding layer\n",
    "    \n",
    "    Returns:\n",
    "    model: A compiled BiLSTM model with TimeDistributed Dense layer for tagging\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input layers for words\n",
    "    word_input = Input(shape=(input_length,), dtype='int32', name='word_input')\n",
    "    \n",
    "    # Create a sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add an embedding layer with pre-trained embedding matrix\n",
    "    embedding_layer = Embedding(len(token2idx)+1 ,\n",
    "                            embedding_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=input_length,\n",
    "                            trainable=False)\n",
    "    model.add(embedding_layer)\n",
    " \n",
    "    # Add a BiLSTM layer\n",
    "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode='concat'))\n",
    "    \n",
    "    # Add a TimeDistributed Dense layer for tagging\n",
    "    model.add(TimeDistributed(Dense(n_tags, activation=\"softmax\")))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36a86b9f-50d0-4fad-b6dd-f9e5971edfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, model):\n",
    "    \"\"\"Train a given Keras model on input-output pairs (X, y).\n",
    "\n",
    "    Args:\n",
    "    - X: the input data\n",
    "    - y: the output data\n",
    "    - model: the model to train.\n",
    "\n",
    "    Returns:\n",
    "    - loss: the training loss at the end of each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    loss = list()\n",
    "    # set epochs to 3 (from 25) (you can change this)\n",
    "    for i in range(3):\n",
    "        # fit model for one epoch on this sequence\n",
    "        hist = model.fit(X, y, batch_size=200, verbose=1, epochs=3, validation_split=0.2)\n",
    "        loss.append(hist.history['loss'][0])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8797695a-591e-484e-93ad-e73ac08ca0a3",
   "metadata": {},
   "source": [
    "### 7. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e28e6d01-3f6d-4e9a-babc-7f62de7c80ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 558, 300)          6890400   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 558, 600)         1442400   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 558, 62)          37262     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,370,062\n",
      "Trainable params: 1,479,662\n",
      "Non-trainable params: 6,890,400\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Epoch 1/3\n",
      "169/169 [==============================] - 1451s 9s/step - loss: 0.0774 - accuracy: 0.9883 - val_loss: 0.0257 - val_accuracy: 0.9943\n",
      "Epoch 2/3\n",
      "169/169 [==============================] - 1429s 8s/step - loss: 0.0242 - accuracy: 0.9941 - val_loss: 0.0222 - val_accuracy: 0.9942\n",
      "Epoch 3/3\n",
      "169/169 [==============================] - 1429s 8s/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 0.0213 - val_accuracy: 0.9943\n",
      "Epoch 1/3\n",
      "169/169 [==============================] - 1425s 8s/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.0206 - val_accuracy: 0.9943\n",
      "Epoch 2/3\n",
      "169/169 [==============================] - 1465s 9s/step - loss: 0.0206 - accuracy: 0.9943 - val_loss: 0.0202 - val_accuracy: 0.9943\n",
      "Epoch 3/3\n",
      "169/169 [==============================] - 1431s 8s/step - loss: 0.0199 - accuracy: 0.9944 - val_loss: 0.0200 - val_accuracy: 0.9943\n",
      "Epoch 1/3\n",
      "169/169 [==============================] - 1447s 9s/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.0196 - val_accuracy: 0.9943\n",
      "Epoch 2/3\n",
      "169/169 [==============================] - 1447s 9s/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 0.0199 - val_accuracy: 0.9943\n",
      "Epoch 3/3\n",
      "169/169 [==============================] - 1413s 8s/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.0196 - val_accuracy: 0.9943\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, concatenate\n",
    "results = pd.DataFrame()\n",
    "embedding_dim = 300 # dimensions of the word2vec vectors\n",
    "model_bilstm_lstm = get_bilstm_lstm_model(embedding_matrix, embedding_dim)\n",
    "plot_model(model_bilstm_lstm)\n",
    "results['with_add_lstm_3ep'] = train_model(train_tokens, train_tags, model_bilstm_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec3feb1-9dda-4a95-b733-90cc5dee0b2c",
   "metadata": {},
   "source": [
    "### 8. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "405f7949-ebd0-4b9d-bc9a-d7939ddc1938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5338/5338 [==============================] - 2546s 477ms/step - loss: 0.0174 - accuracy: 0.9946\n",
      "test loss, test acc: [0.017375651746988297, 0.9946082234382629]\n"
     ]
    }
   ],
   "source": [
    "result = model_bilstm_lstm.evaluate(eval_tokens, np.array(eval_tags), batch_size=1)\n",
    "print(\"test loss, test acc:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4c45cb6-ebe2-4543-b65e-a53be1b90bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(results['with_add_lstm_5ep'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90fc8f9-3d89-4717-bba7-d6307ed96207",
   "metadata": {},
   "source": [
    "### 9. Get model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f44f5a9-c3eb-441c-9068-1fafba54e542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 117s 696ms/step\n"
     ]
    }
   ],
   "source": [
    "# Gets predictions on development set\n",
    "y_pred = model_bilstm_lstm.predict(eval_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1b8887a-f532-4a63-b07c-9ae181038ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37 60 60 ... 60 60 60]\n",
      " [60 60  6 ... 60 60 60]\n",
      " [37 60  6 ... 60 60 60]\n",
      " ...\n",
      " [60 60 60 ... 60 60 60]\n",
      " [60 60 60 ... 60 60 60]\n",
      " [60 60 60 ... 60 60 60]]\n"
     ]
    }
   ],
   "source": [
    "# Gets dimension index with highest probability (--> label)\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "y_eval =  np.argmax(eval_tags, axis=-1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cce8a0b3-0423-4970-92bf-66368626fbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ARG0       0.00      0.00      0.00       478\n",
      "        ARG1       0.00      0.00      0.00       257\n",
      "        ARG2       0.00      0.00      0.00        21\n",
      "    ARGM-ADJ       0.00      0.00      0.00        36\n",
      "    ARGM-ADV       0.00      0.00      0.00        41\n",
      "    ARGM-CAU       0.00      0.00      0.00         5\n",
      "    ARGM-CXN       0.00      0.00      0.00         0\n",
      "    ARGM-DIS       0.00      0.00      0.00       119\n",
      "    ARGM-EXT       0.00      0.00      0.00         6\n",
      "    ARGM-LOC       0.00      0.00      0.00         2\n",
      "    ARGM-LVB       0.00      0.50      0.00         2\n",
      "    ARGM-MNR       0.00      0.00      0.00         9\n",
      "    ARGM-MOD       0.00      0.00      0.00        29\n",
      "    ARGM-NEG       0.00      0.00      0.00         5\n",
      "    ARGM-PRP       0.00      0.00      0.00         1\n",
      "    ARGM-TMP       0.00      0.00      0.00        14\n",
      "      C-ARG1       0.00      0.00      0.00         0\n",
      "  C-ARGM-COM       0.00      0.00      0.00         0\n",
      "  C-ARGM-LOC       0.00      0.00      0.00         0\n",
      "  C-ARGM-MNR       0.00      0.00      0.00         0\n",
      "  R-ARGM-ADJ       0.00      0.00      0.00         0\n",
      "  R-ARGM-ADV       0.00      0.00      0.00         0\n",
      "  R-ARGM-DIR       0.00      0.00      0.00         0\n",
      "           V       0.00      0.00      0.00       230\n",
      "           _       0.00      0.00      0.00      3449\n",
      "\n",
      "    accuracy                           0.00      4704\n",
      "   macro avg       0.00      0.02      0.00      4704\n",
      "weighted avg       0.00      0.00      0.00      4704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Convert the predictions and true labels to their original tag forms (not one-hot encoded)\n",
    "predicted_tags = np.argmax(y_pred, axis=-1)\n",
    "true_tags = np.argmax(np.array(eval_tags), axis=-1)\n",
    "\n",
    "# Create a reverse mapping from tag indices to tag names\n",
    "idx2tag = {i: tag for tag, i in tag2idx.items()}\n",
    "\n",
    "predicted_tags_names = []\n",
    "true_tags_names = []\n",
    "\n",
    "for true_seq, pred_seq in zip(true_tags, predicted_tags):\n",
    "    for true_tag, pred_tag in zip(true_seq.ravel(), pred_seq.ravel()):\n",
    "        # Ignore padding values when both true_tag and pred_tag are padding tags\n",
    "        if not (true_tag == tag2idx[\"C-ARGM-GOL\"] and pred_tag == tag2idx[\"C-ARGM-GOL\"]):\n",
    "            predicted_tags_names.append(idx2tag[pred_tag])\n",
    "            true_tags_names.append(idx2tag[true_tag])\n",
    "\n",
    "predicted_tags_names_filtered, true_tags_names_filtered = [], []\n",
    "            \n",
    "            \n",
    "for predicted_tag_name, true_tag_name in zip(predicted_tags_names, true_tags_names):\n",
    "    if predicted_tag_name is not None and true_tag_name is not None:\n",
    "        predicted_tags_names_filtered.append(predicted_tag_name)\n",
    "        true_tags_names_filtered.append(true_tag_name)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(true_tags_names_filtered, predicted_tags_names_filtered, zero_division=0)\n",
    "\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
